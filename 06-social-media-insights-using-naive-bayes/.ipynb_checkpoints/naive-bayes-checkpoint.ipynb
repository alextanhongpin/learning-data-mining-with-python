{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(input_file):\n",
    "    with open(input_file, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credentials from config file\n",
    "config = load_config('config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorization = twitter.OAuth(config['access_token'], \n",
    "                              config['access_token_secret'],\n",
    "                              config['consumer_key'],\n",
    "                              config['consumer_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = twitter.Twitter(auth=authorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_search_tweet(query, output_filename):\n",
    "    '''\n",
    "    A function that search for 100 tweets of a particular\n",
    "    keyword and writes it to json\n",
    "    '''\n",
    "    if not os.path.exists(output_filename):\n",
    "        with open(output_filename, 'a') as output_file:\n",
    "            print('writing to file')\n",
    "            search_results = t.search.tweets(q=query, count=100)['statuses']\n",
    "            for tweet in search_results:\n",
    "                if 'text' in tweet:\n",
    "                    output_file.write(json.dumps(tweet))\n",
    "                    output_file.write('\\n\\n')\n",
    "\n",
    "output_filename = 'data/python_tweets.json'\n",
    "search_query = 'python'\n",
    "\n",
    "write_search_tweet(search_query, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(input_filename):\n",
    "    '''\n",
    "    A function that loads a file and parse the input\n",
    "    as json\n",
    "    '''\n",
    "    tweets = []\n",
    "    with open(input_filename) as f:\n",
    "        for line in f:\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            tweets.append(json.loads(line))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and classifying the dataset\n",
    "input_filename = 'data/python_tweets.json'\n",
    "tweets = parse_json(input_filename)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(input_filename):\n",
    "    labels = []\n",
    "    if os.path.exists(input_filename):\n",
    "        with open(input_filename) as f:\n",
    "            labels = json.load(f)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "labels_filename = 'data/python_classes.json'\n",
    "labels = load_labels(labels_filename)\n",
    "if labels:\n",
    "    print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_tweet():\n",
    "    return tweets[len(labels)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "function load_next_tweet() {\n",
       "    var code_input = 'get_next_tweet()';\n",
       "    var kernel = IPython.notebook.kernel;\n",
       "    var callbacks = { 'iopub': {'output': handle_output }};\n",
       "    kernel.execute(code_input, callbacks, {silent: false});\n",
       "}\n",
       "\n",
       "function set_label(label) {\n",
       "    var kernel = IPython.notebook.kernel\n",
       "    kernel.execute('labels.append(' + label + ')')\n",
       "    load_next_tweet();\n",
       "}\n",
       "\n",
       "function handle_output(out) {\n",
       "    var res = out.content.data['text/plain'];\n",
       "    $('#tweet_text').html(res);\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "\n",
    "function load_next_tweet() {\n",
    "    var code_input = 'get_next_tweet()';\n",
    "    var kernel = IPython.notebook.kernel;\n",
    "    var callbacks = { 'iopub': {'output': handle_output }};\n",
    "    kernel.execute(code_input, callbacks, {silent: false});\n",
    "}\n",
    "\n",
    "function set_label(label) {\n",
    "    var kernel = IPython.notebook.kernel\n",
    "    kernel.execute('labels.append(' + label + ')')\n",
    "    load_next_tweet();\n",
    "}\n",
    "\n",
    "function handle_output(out) {\n",
    "    var res = out.content.data['text/plain'];\n",
    "    $('#tweet_text').html(res);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div name='tweetbox'>\n",
       "    Instructions: Click in textbox. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n",
       "    Tweet: \n",
       "    <div id='tweet_text' value='text'>Weird</div><br>\n",
       "    <input type='text' id='capture'></input><br>\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "\n",
       "$('#capture').keypress(function (e) {\n",
       "    if (e.which === 48) {\n",
       "        set_label(0)\n",
       "        $('#capture').val('')\n",
       "    } else if (e.which === 49) {\n",
       "        set_label(1)\n",
       "        $('#capture').val('')\n",
       "    }\n",
       "});\n",
       "\n",
       "load_next_tweet();\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<div name='tweetbox'>\n",
    "    Instructions: Click in textbox. Enter a 1 if the tweet is relevant, enter 0 otherwise.<br>\n",
    "    Tweet: \n",
    "    <div id='tweet_text' value='text'>Weird</div><br>\n",
    "    <input type='text' id='capture'></input><br>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "\n",
    "$('#capture').keypress(function (e) {\n",
    "    if (e.which === 48) {\n",
    "        set_label(0)\n",
    "        $('#capture').val('')\n",
    "    } else if (e.which === 49) {\n",
    "        set_label(1)\n",
    "        $('#capture').val('')\n",
    "    }\n",
    "});\n",
    "\n",
    "load_next_tweet();\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "\n",
    "# Write the labels to the file\n",
    "def write_labels(input_filename):\n",
    "    with open(input_filename, 'w') as outf:\n",
    "        json.dump(labels, outf)\n",
    "\n",
    "# write_labels(labels_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "class NLTK_Bow(TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [{ word.lower(): True for word in word_tokenize(document) \n",
    "                if len(word) > 1 and word not in stop_words} \n",
    "                for document in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('bag-of-words', NLTK_Bow()),\n",
    "                     ('vectorizer', DictVectorizer()),\n",
    "                     ('naive-bayes', BernoulliNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(input_filename):\n",
    "    '''\n",
    "    A function that loads a file and parse the input\n",
    "    as json\n",
    "    '''\n",
    "    tweets = []\n",
    "    with open(input_filename) as f:\n",
    "        for line in f:\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            tweets.append(json.loads(line)['text'])\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @PyLadiesMadrid: ¿Quieres aprender Python desde cero? ¡Esta es tu oportunidad! \\nEn PyLadies Madrid arrancamos el año con un nuevo tipo d…'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_filename = 'data/python_tweets.json'\n",
    "tweets = parse_json(input_filename)\n",
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82666667,  0.84057971,  0.82191781])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, tweets, labels, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is: 0.830\n"
     ]
    }
   ],
   "source": [
    "print('score is: {:.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(tweets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access individual steps through the named_steps attributes\n",
    "nb = model.named_steps['naive-bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([378, 237, 408, 149, 412,   0, 151, 344, 248, 343, 101,  80, 140,\n",
       "       239, 170, 342, 167, 163, 382, 326,   8, 304, 496,  85, 417, 282,\n",
       "       276, 415, 315, 273, 271, 100, 193, 277, 153, 156,  73, 160, 380,\n",
       "       367, 174, 158,  93,  81,  90, 399, 398,  99, 435, 267])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_probabilities = nb.feature_log_prob_\n",
    "top_features = np.argsort(-feature_probabilities[1])[:50]\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = model.named_steps['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 python 0.762376237624\n",
      "2 https 0.663366336634\n",
      "3 rt 0.524752475248\n",
      "4 data 0.108910891089\n",
      "5 science 0.0891089108911\n",
      "6 '/my/new/directory 0.0693069306931\n",
      "7 datascience 0.0693069306931\n",
      "8 pathlib.path.mkdir 0.0693069306931\n",
      "9 import 0.0693069306931\n",
      "10 pathlib.path 0.0693069306931\n",
      "11 bigdata 0.0693069306931\n",
      "12 amp 0.0693069306931\n",
      "13 create 0.0693069306931\n",
      "14 htt… 0.0693069306931\n",
      "15 django 0.0693069306931\n",
      "16 pathlib 0.0693069306931\n",
      "17 directories 0.0693069306931\n",
      "18 developer 0.0693069306931\n",
      "19 pythonweekly 0.0693069306931\n",
      "20 new 0.0693069306931\n",
      "21 .mkdir 0.0693069306931\n",
      "22 method 0.0693069306931\n",
      "23 with 0.0594059405941\n",
      "24 answer 0.049504950495\n",
      "25 server 0.049504950495\n",
      "26 libsvm 0.049504950495\n",
      "27 learn 0.049504950495\n",
      "28 scripting 0.049504950495\n",
      "29 movie-ratings 0.049504950495\n",
      "30 language 0.049504950495\n",
      "31 know 0.049504950495\n",
      "32 big 0.049504950495\n",
      "33 exploratory 0.049504950495\n",
      "34 learning 0.049504950495\n",
      "35 days 0.049504950495\n",
      "36 deep_learningz 0.049504950495\n",
      "37 accelerated 0.049504950495\n",
      "38 detection 0.049504950495\n",
      "39 python_tip 0.049504950495\n",
      "40 programming 0.049504950495\n",
      "41 drop-in 0.049504950495\n",
      "42 deliprao 0.049504950495\n",
      "43 author 0.049504950495\n",
      "44 analysis 0.049504950495\n",
      "45 artificial 0.049504950495\n",
      "46 replacement 0.049504950495\n",
      "47 reinforcement 0.049504950495\n",
      "48 based 0.049504950495\n",
      "49 stack 0.049504950495\n",
      "50 kdnuggets 0.049504950495\n"
     ]
    }
   ],
   "source": [
    "for i, feature_index in enumerate(top_features):\n",
    "    print(i + 1, dv.feature_names_[feature_index], np.exp(feature_probabilities[1][feature_index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
